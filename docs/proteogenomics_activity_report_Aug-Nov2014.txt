Firstly, we've been working on improving trackhub support in order to overcome some of the limitations of the current trackhub specification. Currently, the trackhub provider is forced to maintain a specific directory structure with a set of files referring to each other and with a format which is solely under UCSC control. The format defining track data and display configuration is a kind of moving target, where tabs have semantic value and define difficult to parse relationships among the components of a trackhub repository. Moreover, the specification for metadata extraction is deprecated and will not be officially supported in the future. This is of course a problem if we want to support search operations over trackhubs. 
To overcome these problems, we have proposed to adopt JSON to completely characterise a trackhub database, using a single file which can be easily understood by both humans and machines and which is the de facto standard for data interchange over the Internet. We have adopted a schema from the JSON schema specification (http://www.json-schema.org) in order to describe the structure of valid trackhub documents. We have continuosly refined the specification using feedback from the Blueprint project and the Proteomics team at the EBI: we are now at the third draft of the specification, with support for epigenomics and proteomics metadata and for all major display and configuration properties of all track types in the UCSC trackhub database specification.

Secondly, we've been working on the analysis, design and prototype implementation of the trackhub registry. The registry is designed to work as a centralised, global collection of trackhub servers, which allows third party providers to advertise and publish their trackhubs, and users to search and discover track data they are interested in, and load it in the favourite genome browser. 
We have explored different technologies in order to implement the storage and/or search engine: PostgreSQL, Solr and Elasticsearch, the last two being very powerful search frameworks but with the ability to serve as persistence engines as well. After some investigations, we have decided to work exclusively with Elasticsearch, as Solr does not provide the ability to index arbitrarily complex (i.e. hierchically structured) documents, like the ones belonging to the JSON specificationa above.
We have then started the development of the prototype web application using the Perl Catalyst framework. We have implemented: 1. basic drivers to interface withe the Elasticsearch indexing and search APIs by extending modules found on the CPAN archive; 2. a Catalyst plug-in to handle authentication/authorisation using an Elasticsearch store. Using these components, we have been able to design and implement RESTful web services to interact with trackhub providers with operations to manage token-based API authentication, and CRUD operations to support the publication process. We have also prototyped the structure and appearance of the website using the Bootstrap CSS and Javascript framework, with a basic search interface, login/registration/administration pages and authorisation-based pages with operations for registered trackhub providers.

